{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Maximum Entropy Algorithm\n",
    "As derived by Nunez and Llacer (1990) and outlined by Carasso (1999).\n",
    "\n",
    "This algorithm was derived directly from Bayes' Theorem by maximizing the posterior probability. The prior probability p(f) is given using Maxwell-Boltzmann statistics and the global probability p(g|f) is defined with Poisson noise in the blurred image g. \n",
    "\n",
    "\n",
    "Required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.api:The ipywidgets GUI elements are not available, probably because the hyperspy_gui_ipywidgets package is not installed.\n",
      "WARNING:hyperspy.api:The traitsui GUI elements are not available, probably because the hyperspy_gui_traitsui package is not installed.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "from ncempy.io import dm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import peak_widths, find_peaks\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text files\n",
    "def txtconverter(numpy_array):\n",
    "    file = str(numpy_array).replace('[','')\n",
    "    file = file.replace(']','')\n",
    "    data = np.fromstring(file, sep=',')\n",
    "    return data\n",
    "\n",
    "#sorting data into counts and eV\n",
    "def find_counts(data):\n",
    "    counts = data[1:-1:2]\n",
    "    return counts\n",
    "\n",
    "def find_ev(data):\n",
    "    ev = data[0:-1:2]\n",
    "    return ev\n",
    "\n",
    "#plot the spectrum with HyperSpy\n",
    "def hyperspy_plot(ev, counts):\n",
    "    s = hs.signals.EELSSpectrum(counts)\n",
    "    s.axes_manager[0].scale = np.diff(ev).mean()\n",
    "    s.axes_manager[0].unit = 'eV'\n",
    "    s.axes_manager[0].offset = ev[0]\n",
    "    s.axes_manager[0].name = 'Energy'\n",
    "    return s\n",
    "\n",
    "#FWHM comparisons\n",
    "def FWHM_testing(sigma, gamma, hs_signal, hs_deconvolved, height):\n",
    "    \n",
    "    peaks1, _ = find_peaks(hs_signal, height=1)\n",
    "    results_half_signal = peak_widths(hs_signal, peaks1, rel_height=0.5)\n",
    "    \n",
    "    peaks2, _ = find_peaks(hs_deconvolved, height=height)\n",
    "    results_half_deconvolved = peak_widths(hs_deconvolved, peaks2, rel_height=0.5)\n",
    "    \n",
    "    FWHM_signal = 4 / 1000 * results_half_signal[0]\n",
    "    FWHM_deconvolved = 4 / 1000 * results_half_deconvolved[0]\n",
    "    \n",
    "    Lorentzian_FWHM = 2 * gamma\n",
    "    Gaussian_FWHM = 2.335 * sigma\n",
    "    \n",
    "    relative_error = abs((FWHM_deconvolved[0] - Lorentzian_FWHM)/Lorentzian_FWHM*100)\n",
    "    \n",
    "    print(\"FWHM of signal =\", FWHM_signal[0], \"eV\", \n",
    "          \"\\nFWHM of deconvolved =\", FWHM_deconvolved[0], \"eV\", \n",
    "          \"\\nFWHM of Lorentzian =\", Lorentzian_FWHM, \"eV\", \n",
    "          \"\\nRelative error =\",  math.trunc(relative_error), \"%\\n\")\n",
    "    \n",
    "#plotting the noise\n",
    "def noise(Spectrum, deconvolved, PSF):\n",
    "    noise = np.subtract(Spectrum, np.convolve(deconvolved, PSF, mode='same'))\n",
    "    return noise\n",
    "\n",
    "#Richardson-Lucy algorithm (code from Edson Bellido)\n",
    "def RL(iterations, PSF, Spectrum):\n",
    "    RL4 = np.copy(Spectrum)\n",
    "    for i in range(iterations):\n",
    "        RL1 = np.convolve(PSF, RL4, mode='same')\n",
    "        RL2 = np.divide(Spectrum,RL1)\n",
    "        RL3 = np.convolve(PSF, RL2, mode='same')\n",
    "        RL4 = np.multiply(RL3, RL4)\n",
    "    return RL4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file as numpy array\n",
    "Signal = np.loadtxt(\"D:\\Downloads\\Signal1.txt\",dtype=\"str\")\n",
    "PSF = np.loadtxt(\"D:\\Downloads\\PSF1.txt\", dtype='str')\n",
    "Real = np.loadtxt(\"D:\\Downloads\\Real1.txt\", dtype='str')\n",
    "\n",
    "#convert text file to usable numpy array\n",
    "signal = txtconverter(Signal)\n",
    "psf = txtconverter(PSF)\n",
    "real = txtconverter(Real)\n",
    "\n",
    "#separate data into counts and ev\n",
    "signal_counts = find_counts(signal)\n",
    "psf_counts = find_counts(psf)\n",
    "real_counts = find_counts(real)\n",
    "ev = find_ev(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEM Algorithm\n",
    "\n",
    "This algorithm contains two adjustable parameters that are used to manipulate the convergence rate and smoothing of the deconvolution. The constant C has a small affect on the convergence rate, but is primarily existent to ensure positivity. The constant rho is known as the \"sharpness\" parameter, as rho increases, the deconvolution process behaves more like the Richardson-Lucy algorithm, and as rho decreases, the prior probability p(f) becomes dominant, smoothing the high frequency information.\n",
    "\n",
    "1 <= Rho <= 20 (otherwise behaves like RL)\n",
    "\n",
    "C >= Rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MEM(iterations, PSF, Spectrum):\n",
    "    rho = 10\n",
    "    C = 15\n",
    "    N = np.sum(Spectrum)\n",
    "    \n",
    "    MEM = Spectrum\n",
    "    for i in range(iterations):\n",
    "        A1 = np.convolve(PSF, MEM, mode='same')\n",
    "        A2 = np.divide(Spectrum, A1)\n",
    "        A3 = np.convolve(PSF, A2, mode='same')\n",
    "        A4 = np.subtract(np.multiply(rho, A3), rho)\n",
    "        A5 = np.add(np.subtract(A4, np.log10(MEM)), C)\n",
    "        A6 = N * (np.sum(np.multiply(MEM, A5)))**(-1)\n",
    "        \n",
    "        MEM1 = np.convolve(PSF, MEM, mode='same')\n",
    "        MEM2 = np.divide(Spectrum, MEM1)\n",
    "        MEM3 = np.convolve(PSF, MEM2, mode='same')\n",
    "        MEM4 = np.subtract(np.multiply(rho, MEM3), rho)\n",
    "        MEM5 = np.add(np.subtract(MEM4, np.log10(MEM)), C)\n",
    "        MEM6 = np.multiply(np.multiply(MEM, MEM5), A6)\n",
    "        MEM = MEM6\n",
    "    return MEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between MEM and RL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEM_deconvolve = MEM(10, psf_counts, signal_counts)\n",
    "s_MEM = hyperspy_plot(ev, MEM_deconvolve)\n",
    "\n",
    "RL_deconvolve = RL(10, psf_counts, signal_counts)\n",
    "s_RL = hyperspy_plot(ev, RL_deconvolve)\n",
    "\n",
    "s_signal = hyperspy_plot(ev, signal_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEM\n",
      "FWHM of signal = 0.32627560766739383 eV \n",
      "FWHM of deconvolved = 0.26104274337774724 eV \n",
      "FWHM of Lorentzian = 0.2 eV \n",
      "Relative error = 30 %\n",
      "\n",
      "RL\n",
      "FWHM of signal = 0.32627560766739383 eV \n",
      "FWHM of deconvolved = 0.23908186476795754 eV \n",
      "FWHM of Lorentzian = 0.2 eV \n",
      "Relative error = 19 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MEM\")\n",
    "FWHM_MEM = FWHM_testing(0.1, 0.1, s_signal, s_MEM, 0.5)\n",
    "\n",
    "print(\"RL\")\n",
    "FWHM_RL = FWHM_testing(0.1, 0.1, s_signal, s_RL, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_MEM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_RL.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_signal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
